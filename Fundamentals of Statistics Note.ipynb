{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From William Leo: Techniques for Nuclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Statistics is used to treat uncertainties inherent in the measured data and to be able to draw meaningful & fair conclusions from this result.\n",
    "\n",
    "Before performing measurements, one must consider:\n",
    "1. Tolerances required for the apparatus\n",
    "2. Measuring times involved\n",
    "both as a function of the desired precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of Probability Distributions\n",
    "\n",
    "Statistics assumes random process, therefore the outcome of a measurements fluctuate from trial to trial and it is impossible to predict the outcome of next trial. \n",
    "\n",
    "- **Probability density**: is used to describe the expected frequency or occurence of each possible outcome. \n",
    "\n",
    "- **Random variable**: is the possible outcome from measurement, and is distributed either as discrete probability density of continuous PDF.\n",
    "\n",
    "- **Cumulative distributions**: Just integration or summation over PDF. Defined mathematically as<br>\n",
    "$\\begin{aligned}\n",
    "P(x_1\\leq x \\leq x_2) &= \\int_{x_1}^{x_2}P(x)dx , \\text{for continuous PDF}\\\\\n",
    "P(x_1\\leq x \\leq x_2) &= \\sum_{i=1}^{2}P(x_i)\\text{, for discrete PDF}\n",
    "\\end{aligned}$\n",
    "\n",
    "- **Expectation values**:<br> \n",
    "$\\begin{aligned}\n",
    "E[x] &= \\int x P(x)dx , \\text{for continuous PDF}\\\\\n",
    "E[x] &= \\sum x_iP(x_i)\\text{, for discrete PDF}\n",
    "\\end{aligned}$\n",
    "\n",
    "- **Distribution Moments: The mean and variance**: In general, a prob dist may be characterized by its <u>moments</u>. The r-th moment of x about some fixed point $x_0$ is just $E[(x-x_0)^r]$. Therefore:\n",
    "    - The mean or average = first moment about zero, $\\mu = E[x]$. It is important to distinguish between <i>theoretical mean</i> calculated from theoretical PDF vs. <i>experimental mean</i> taken from averaging over data points.\n",
    "    - The variance ($\\sigma^2$)= second moment about the mean, <br>\n",
    "    $\\sigma^2 = E[(x-\\mu)^2]=\\int (x-\\mu)^2 P(x) dx$\n",
    "    - Skewness = third moment about the mean. This will give a measure whether the PDF is symmetric or asymmetric. \n",
    "    \n",
    "- **Covariance**: for multivariate distribution, $P(x,y,z,...)$, a new quantity can be defined between pairs of random variables:<br> \n",
    "$cov(x,y) = E[(x-\\mu_x)(y-\\mu_y)]$, and between the combinations of the rest random vars.<br> \n",
    "Covariance is a measure of the <u>linear correlation between the two variables</u>. This is related to and can be expressed better with $\\rightarrow$\n",
    "\n",
    "- **Correlation coefficient**:<br> \n",
    "$\\rho = \\dfrac{cov(x,y)}{\\sigma_x \\sigma_y}$<br>\n",
    ", where $|\\rho| = 1$ indicates perfect linear correlation<br>\n",
    "and $\\rho = 0$ indicates linear independence. <br>\n",
    "It is only <u>linearly independent</u>, since if the two rand vars related by $y=x^2$, then $\\rho=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Probability Distributions\n",
    "#### <u>1. Binomial Distribution</u>\n",
    "\n",
    "This is the case when the outcome is only either Success or Failure. <br>\n",
    "Probability of $r$ successes in $N$ tries given the success rate in a single trial $p$ is given by the <b>Binomial Distribution</b>:<br>\n",
    "$\\begin{equation}\n",
    "P(r) = \\dfrac{N!}{r!(N-r)!}p^r(1-p)^{N-r}\n",
    "\\end{equation}$\n",
    "    \n",
    "Characteristics of this PDF are:\n",
    "- Mean: $\\mu = Np$\n",
    "- Variance: $\\sigma^2 = Np(1-p)$\n",
    "\n",
    "In the limit of large N ($N \\geq 30$) and not too small p ($p\\geq 0.05$): binomial dist $\\rightarrow$ Gaussian dist with the same mean and variance as above.<br>\n",
    "\n",
    "#### <u>2. Poisson Distribution</u>\n",
    "\n",
    "As mentioned before, occur as the limit of binomial distribution when $p\\rightarrow 0$ and $N\\rightarrow \\infty$,i.e. the single trial probability is very small but the number of trials is so large that there is nevertheless a reasonable rate of events. Examples are radioactive decays, particle reactions.\n",
    "\n",
    "This dist is written as:<br>\n",
    "$P(r) = \\dfrac{\\mu^r e^{-\\mu}}{r!}$<br>\n",
    ", and is discrete. <br>\n",
    "This can also be modified by rewriting $\\mu = \\lambda t$, where $\\lambda$: mean[/sec]  and t:time[sec] \n",
    "\n",
    "Characteristics of this PDF:\n",
    "- Mean = mean ($\\mu$)\n",
    "- Variance = mean = $\\mu$, and std = $\\sqrt{\\mu}$.\n",
    "\n",
    "This distribution is not symmetric, and the max value does not correspond to the mean. As $\\mu$ becomes large ($\\mu \\geq 20$), the distribution becomes more and more symmetric and approaches Gaussian dist. \n",
    "\n",
    "#### <u>3. Gaussian Distribution</u>\n",
    "Measurement errors and in particular, instrumental errors, are generally Gaussian distributed. \n",
    "\n",
    "It is given as:<br>\n",
    "$P(x) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\bigg(-\\dfrac{(x-\\mu)^2}{2\\sigma^2}\\bigg)$\n",
    "\n",
    "Characteristics of this PDF:\n",
    "- Mean: $\\mu$\n",
    "- Variance: $\\sigma^2$\n",
    "- FWHM = $2\\sigma\\sqrt{2 ln2} = 2.35\\sigma$\n",
    "- Area (cumulative probability) within:\n",
    "    - $\\mu\\pm \\sigma$ = 68%\n",
    "    - $\\mu\\pm 2\\sigma$ = 95%\n",
    "\n",
    "It is usually tabulated as *reduced Gaussian distribution* with $\\mu_z = 0$ and $\\sigma_z^2 =1$. All Gaussian can be transformed to this *reduced* form via change of variable:$z = \\frac{x-\\mu}{\\sigma}$\n",
    "\n",
    "#### <u>4. Chi-square Distribution</u>\n",
    "This is particularly useful for testing the *goodness-of-fit* of model to data. A variable *chi-square* is defined as the following: a set of *n* independent random variables $x_i$, distributed as **Gaussian** with theoretical means $\\mu_i$ and std $\\sigma_i$, the sum is known as *chi-square*:<br>\n",
    "$\\chi^2 = \\sigma_{i=1}^n \\dfrac{x_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "The distribution follows the following PDF, with $u=\\chi^2$:<br>\n",
    "$P(u)du = \\dfrac{(u/2)^{(\\nu/2)-1} exp(-u/2)}{2\\Gamma(\\nu/2)}du$<br>\n",
    "where $\\nu$ is the *degrees of freedom* and is the sole parameter of the distribution. \n",
    "\n",
    "The characteristics of this PDF are:\n",
    "- Mean: $\\mu = \\nu$\n",
    "- Variance: $\\sigma^2 = 2\\nu$\n",
    "\n",
    "This distribution can be used to see if the obtained value of $\\chi^2$ obtained from fitting is probable or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Parameter Estimation: Maximum Likelihood Method\n",
    "\n",
    "Sampling: Experimental method by which information can be obtained about the parameters of an unknown distribution. <br>\n",
    "\n",
    "Estimation: Method to determine the best value from given data sample, which minimizes the variance between the estimate and the true value. <br>\n",
    "This consists of two parts:\n",
    "1. Determining the best estimate\n",
    "2. Determining the uncertainty of the estimate<br>\n",
    "\n",
    "The most widely accepted estimation method is **the principle of maximum likelihood**\n",
    "\n",
    "\n",
    "<u>**1. Determining the best estimate**</u>\n",
    "\n",
    "Sample mean:<br>\n",
    "$\\overline{x} = \\frac{1}{n}\\Sigma_{i=1}^n x_i$<br>\n",
    "In the limit $n\\rightarrow \\infty$, $\\overline{x}\\rightarrow \\mu$ (theoretical mean)\n",
    "\n",
    "Sample variance:<br>\n",
    "$s^2 = \\frac{1}{n}\\Sigma_{i=1}^n (x_i-\\overline{x})^2$ <br>\n",
    "\n",
    "Sample covariance:<br>\n",
    "$cov(x,y) = \\frac{1}{n}\\Sigma_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})$ <br>\n",
    "\n",
    "**The Maximum Likelihood Method**\n",
    "\n",
    "This is only applicable if the form of the theoretical distribution from which the sample is taken is known. For most measurements in physics, this is either *Gaussian* or *Poisson*. This statement can be written mathematically as:<br>\n",
    "<blockquote>\n",
    "Suppose we have a sample of *n* independent observations $x_1, x_2, ..., x_n$ from a theoretical distribution $f(x|\\theta)$ and we want to estimate the parameter $\\theta$.<br>\n",
    "    \n",
    "We first calculate the <u>likelihood function</u>:<br>\n",
    "$L(\\theta|x) = f(x_1|\\theta)f(x_2|\\theta)...f(x_n|\\theta)$<br>\n",
    ", which is the probability of observing all x values. <br>\n",
    "\n",
    "Thus, the parameter $\\theta$ must be such that L is a maximum by solving:<br>\n",
    "$\\dfrac{dL}{d\\theta}=0$<br>\n",
    "and in its easier form:<br>\n",
    "$\\dfrac{d(ln L)}{d\\theta}=0$<br>\n",
    "\n",
    "The solution $\\hat{\\theta}$, is know as the maximum likelihood *estimator* for the true value $\\theta$.<br>\n",
    "Associated with this estimated $\\hat{\\theta}$ is the error:<br>\n",
    "$\\sigma^2(\\hat{\\theta}) \\approxeq -\\bigg(\\dfrac{d^2 ln L}{d\\theta^2}\\bigg)^{-1}$<br>\n",
    "or in general is *the matrix of the second derivatives*<br>\n",
    "$U_{ij} = -\\dfrac{\\partial^2 ln L}{\\partial\\theta_i\\partial\\theta_j}$<br>\n",
    "$\\sigma^2(\\hat{\\theta}) \\approxeq (U^{-1})_{ii}$\n",
    "</blockquote>\n",
    "\n",
    "**Estimator for the Poisson Distribution**\n",
    "\n",
    "Suppose we have *n* measurements of samples: $x_1, x_2, ..., x_n$ from a Poisson distribution with mean $\\mu$ (i.e. we randomly sample Poisson distribution *n*-times).\n",
    "\n",
    "Using Princ of Max Likelihood, the estimate for:<br>\n",
    "- Estimate of the mean:<br>\n",
    "$\\hat{\\mu} = \\frac{1}{n}\\Sigma x_i = \\overline{x}$<br>\n",
    ", which is just the sample mean\n",
    "\n",
    "- Standard error of the mean:<br> \n",
    "General results:<br> \n",
    "$\\sigma^2(\\overline{x})= \\frac{\\sigma^2}{n}$ (Look at Leo's book for derivation)<br>\n",
    "For Poisson dist: $\\sigma^2 = \\mu$<br>\n",
    "$\\sigma(\\hat{\\mu}) = \\sqrt{\\frac{\\mu}{n}} \\approxeq \\sqrt{\\frac{\\hat{\\mu}}{n}} = \\sqrt{\\frac{\\overline{x}}{n}}$\n",
    "\n",
    "**Estimator for the Gaussian Distribution**\n",
    "\n",
    "Similarly, using Princ of Max Likelihood, the estimate for:<br>\n",
    "- $\\hat{\\mu} = \\frac{1}{n}\\Sigma x_i = \\overline{x}$\n",
    "- Standard error of the mean:<br> \n",
    "Again, using general result:<br>\n",
    "$\\sigma^2(\\overline{x})= \\frac{\\sigma^2}{n}$<br>\n",
    "The value of $\\sigma$ itself, however, needs to be estimated as:<br>\n",
    "$\\hat{\\sigma}^2 = \\dfrac{\\Sigma(x_i - \\overline{x})^2}{n-1} = \\frac{n}{n-1} s^2$, $s^2$: sample variance\n",
    "\n",
    "**The Weighted Mean**<br>\n",
    "This is to combine two or more measurements of the same quantity with different errors.<br>\n",
    "$\\hat{\\mu}= \\dfrac{\\Sigma x_i/\\sigma_i^2}{\\Sigma 1/\\sigma_i^2}$<br>\n",
    ", and error on the weighted mean:<br>\n",
    "$\\sigma^2(\\hat{\\mu})=\\dfrac{1}{\\Sigma 1/\\sigma^2_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
