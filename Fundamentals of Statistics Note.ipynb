{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From William Leo: Techniques for Nuclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Statistics is used to treat uncertainties inherent in the measured data and to be able to draw meaningful & fair conclusions from this result.\n",
    "\n",
    "Before performing measurements, one must consider:\n",
    "1. Tolerances required for the apparatus\n",
    "2. Measuring times involved\n",
    "both as a function of the desired precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of Probability Distributions\n",
    "\n",
    "Statistics assumes random process, therefore the outcome of a measurements fluctuate from trial to trial and it is impossible to predict the outcome of next trial. \n",
    "\n",
    "- **Probability density**: is used to describe the expected frequency or occurence of each possible outcome. \n",
    "\n",
    "- **Random variable**: is the possible outcome from measurement, and is distributed either as discrete probability density of continuous PDF.\n",
    "\n",
    "- **Cumulative distributions**: Just integration or summation over PDF. Defined mathematically as<br>\n",
    "$\\begin{aligned}\n",
    "P(x_1\\leq x \\leq x_2) &= \\int_{x_1}^{x_2}P(x)dx , \\text{for continuous PDF}\\\\\n",
    "P(x_1\\leq x \\leq x_2) &= \\sum_{i=1}^{2}P(x_i)\\text{, for discrete PDF}\n",
    "\\end{aligned}$\n",
    "\n",
    "- **Expectation values**:<br> \n",
    "$\\begin{aligned}\n",
    "E[x] &= \\int x P(x)dx , \\text{for continuous PDF}\\\\\n",
    "E[x] &= \\sum x_iP(x_i)\\text{, for discrete PDF}\n",
    "\\end{aligned}$\n",
    "\n",
    "- **Distribution Moments: The mean and variance**: In general, a prob dist may be characterized by its <u>moments</u>. The r-th moment of x about some fixed point $x_0$ is just $E[(x-x_0)^r]$. Therefore:\n",
    "    - The mean or average = first moment about zero, $\\mu = E[x]$. It is important to distinguish between <i>theoretical mean</i> calculated from theoretical PDF vs. <i>experimental mean</i> taken from averaging over data points.\n",
    "    - The variance ($\\sigma^2$)= second moment about the mean, <br>\n",
    "    $\\sigma^2 = E[(x-\\mu)^2]=\\int (x-\\mu)^2 P(x) dx$\n",
    "    - Skewness = third moment about the mean. This will give a measure whether the PDF is symmetric or asymmetric. \n",
    "    \n",
    "- **Covariance**: for multivariate distribution, $P(x,y,z,...)$, a new quantity can be defined between pairs of random variables:<br> \n",
    "$cov(x,y) = E[(x-\\mu_x)(y-\\mu_y)]$, and between the combinations of the rest random vars.<br> \n",
    "Covariance is a measure of the <u>linear correlation between the two variables</u>. This is related to and can be expressed better with $\\rightarrow$\n",
    "\n",
    "- **Correlation coefficient**:<br> \n",
    "$\\rho = \\dfrac{cov(x,y)}{\\sigma_x \\sigma_y}$<br>\n",
    ", where $|\\rho| = 1$ indicates perfect linear correlation<br>\n",
    "and $\\rho = 0$ indicates linear independence. <br>\n",
    "It is only <u>linearly independent</u>, since if the two rand vars related by $y=x^2$, then $\\rho=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Probability Distributions\n",
    "#### <u>1. Binomial Distribution</u>\n",
    "\n",
    "This is the case when the outcome is only either Success or Failure. <br>\n",
    "Probability of $r$ successes in $N$ tries given the success rate in a single trial $p$ is given by the <b>Binomial Distribution</b>:<br>\n",
    "$\\begin{equation}\n",
    "P(r) = \\dfrac{N!}{r!(N-r)!}p^r(1-p)^{N-r}\n",
    "\\end{equation}$\n",
    "    \n",
    "Characteristics of this PDF are:\n",
    "- Mean: $\\mu = Np$\n",
    "- Variance: $\\sigma^2 = Np(1-p)$\n",
    "\n",
    "In the limit of large N ($N \\geq 30$) and not too small p ($p\\geq 0.05$): binomial dist $\\rightarrow$ Gaussian dist with the same mean and variance as above.<br>\n",
    "\n",
    "#### <u>2. Poisson Distribution</u>\n",
    "\n",
    "As mentioned before, occur as the limit of binomial distribution when $p\\rightarrow 0$ and $N\\rightarrow \\infty$,i.e. the single trial probability is very small but the number of trials is so large that there is nevertheless a reasonable rate of events. Examples are radioactive decays, particle reactions.\n",
    "\n",
    "This dist is written as:<br>\n",
    "$P(r) = \\dfrac{\\mu^r e^{-\\mu}}{r!}$<br>\n",
    ", and is discrete. <br>\n",
    "This can also be modified by rewriting $\\mu = \\lambda t$, where $\\lambda$: mean[/sec]  and t:time[sec] \n",
    "\n",
    "Characteristics of this PDF:\n",
    "- Mean = mean ($\\mu$)\n",
    "- Variance = mean = $\\mu$, and std = $\\sqrt{\\mu}$.\n",
    "\n",
    "This distribution is not symmetric, and the max value does not correspond to the mean. As $\\mu$ becomes large ($\\mu \\geq 20$), the distribution becomes more and more symmetric and approaches Gaussian dist. \n",
    "\n",
    "#### <u>3. Gaussian Distribution</u>\n",
    "Measurement errors and in particular, instrumental errors, are generally Gaussian distributed. \n",
    "\n",
    "It is given as:<br>\n",
    "$P(x) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\bigg(-\\dfrac{(x-\\mu)^2}{2\\sigma^2}\\bigg)$\n",
    "\n",
    "Characteristics of this PDF:\n",
    "- Mean: $\\mu$\n",
    "- Variance: $\\sigma^2$\n",
    "- FWHM = $2\\sigma\\sqrt{2 ln2} = 2.35\\sigma$\n",
    "- Area (cumulative probability) within:\n",
    "    - $\\mu\\pm \\sigma$ = 68%\n",
    "    - $\\mu\\pm 2\\sigma$ = 95%\n",
    "\n",
    "It is usually tabulated as *reduced Gaussian distribution* with $\\mu_z = 0$ and $\\sigma_z^2 =1$. All Gaussian can be transformed to this *reduced* form via change of variable:$z = \\frac{x-\\mu}{\\sigma}$\n",
    "\n",
    "#### <u>4. Chi-square Distribution</u>\n",
    "This is particularly useful for testing the *goodness-of-fit* of model to data. A variable *chi-square* is defined as the following: a set of *n* independent random variables $x_i$, distributed as **Gaussian** with theoretical means $\\mu_i$ and std $\\sigma_i$, the sum is known as *chi-square*:<br>\n",
    "$\\chi^2 = \\Sigma_{i=1}^n \\bigg(\\dfrac{x_i - \\mu_i}{\\sigma_i}\\bigg)^2$\n",
    "\n",
    "The distribution follows the following PDF, with $u=\\chi^2$:<br>\n",
    "$P(u)du = \\dfrac{(u/2)^{(\\nu/2)-1} exp(-u/2)}{2\\Gamma(\\nu/2)}du$<br>\n",
    "where $\\nu$ is the *degrees of freedom* and is the sole parameter of the distribution. \n",
    "\n",
    "The characteristics of this PDF are:\n",
    "- Mean: $\\mu = \\nu$\n",
    "- Variance: $\\sigma^2 = 2\\nu$\n",
    "\n",
    "This distribution can be used to see if the obtained value of $\\chi^2$ obtained from fitting is probable or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Parameter Estimation: Maximum Likelihood Method\n",
    "\n",
    "Sampling: Experimental method by which information can be obtained about the parameters of an unknown distribution. <br>\n",
    "\n",
    "Estimation: Method to determine the best value from given data sample, which minimizes the variance between the estimate and the true value. <br>\n",
    "This consists of two parts:\n",
    "1. Determining the best estimate\n",
    "2. Determining the uncertainty of the estimate<br>\n",
    "\n",
    "The most widely accepted estimation method is **the principle of maximum likelihood**\n",
    "\n",
    "\n",
    "<u>**1. Determining the best estimate**</u>\n",
    "\n",
    "Sample mean:<br>\n",
    "$\\overline{x} = \\frac{1}{n}\\Sigma_{i=1}^n x_i$<br>\n",
    "In the limit $n\\rightarrow \\infty$, $\\overline{x}\\rightarrow \\mu$ (theoretical mean)\n",
    "\n",
    "Sample variance:<br>\n",
    "$s^2 = \\frac{1}{n}\\Sigma_{i=1}^n (x_i-\\overline{x})^2$ <br>\n",
    "\n",
    "Sample covariance:<br>\n",
    "$cov(x,y) = \\frac{1}{n}\\Sigma_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})$ <br>\n",
    "\n",
    "**The Maximum Likelihood Method**\n",
    "\n",
    "This is only applicable if the form of the theoretical distribution from which the sample is taken is known. For most measurements in physics, this is either *Gaussian* or *Poisson*. This statement can be written mathematically as:<br>\n",
    "<blockquote>\n",
    "Suppose we have a sample of *n* independent observations $x_1, x_2, ..., x_n$ from a theoretical distribution $f(x|\\theta)$ and we want to estimate the parameter $\\theta$.<br>\n",
    "    \n",
    "We first calculate the <u>likelihood function</u>:<br>\n",
    "$L(\\theta|x) = f(x_1|\\theta)f(x_2|\\theta)...f(x_n|\\theta)$<br>\n",
    ", which is the probability of observing all x values. <br>\n",
    "\n",
    "Thus, the parameter $\\theta$ must be such that L is a maximum by solving:<br>\n",
    "$\\dfrac{dL}{d\\theta}=0$<br>\n",
    "and in its easier form:<br>\n",
    "$\\dfrac{d(ln L)}{d\\theta}=0$<br>\n",
    "\n",
    "The solution $\\hat{\\theta}$, is know as the maximum likelihood *estimator* for the true value $\\theta$.<br>\n",
    "Associated with this estimated $\\hat{\\theta}$ is the error:<br>\n",
    "$\\sigma^2(\\hat{\\theta}) \\approxeq -\\bigg(\\dfrac{d^2 ln L}{d\\theta^2}\\bigg)^{-1}$<br>\n",
    "or in general is *the matrix of the second derivatives*<br>\n",
    "$U_{ij} = -\\dfrac{\\partial^2 ln L}{\\partial\\theta_i\\partial\\theta_j}$<br>\n",
    "$\\sigma^2(\\hat{\\theta}) \\approxeq (U^{-1})_{ii}$\n",
    "</blockquote>\n",
    "\n",
    "**Estimator for the Poisson Distribution**\n",
    "\n",
    "Suppose we have *n* measurements of samples: $x_1, x_2, ..., x_n$ from a Poisson distribution with mean $\\mu$ (i.e. we randomly sample Poisson distribution *n*-times).\n",
    "\n",
    "Using Princ of Max Likelihood, the estimate for:<br>\n",
    "- Estimate of the mean:<br>\n",
    "$\\hat{\\mu} = \\frac{1}{n}\\Sigma x_i = \\overline{x}$<br>\n",
    ", which is just the sample mean\n",
    "\n",
    "- Standard error of the mean:<br> \n",
    "General results:<br> \n",
    "$\\sigma^2(\\overline{x})= \\frac{\\sigma^2}{n}$ (Look at Leo's book for derivation)<br>\n",
    "For Poisson dist: $\\sigma^2 = \\mu$<br>\n",
    "$\\sigma(\\hat{\\mu}) = \\sqrt{\\frac{\\mu}{n}} \\approxeq \\sqrt{\\frac{\\hat{\\mu}}{n}} = \\sqrt{\\frac{\\overline{x}}{n}}$\n",
    "\n",
    "**Estimator for the Gaussian Distribution**\n",
    "\n",
    "Similarly, using Princ of Max Likelihood, the estimate for:<br>\n",
    "- $\\hat{\\mu} = \\frac{1}{n}\\Sigma x_i = \\overline{x}$\n",
    "- Standard error of the mean:<br> \n",
    "Again, using general result:<br>\n",
    "$\\sigma^2(\\overline{x})= \\frac{\\sigma^2}{n}$<br>\n",
    "The value of $\\sigma$ itself, however, needs to be estimated as:<br>\n",
    "$\\hat{\\sigma}^2 = \\dfrac{\\Sigma(x_i - \\overline{x})^2}{n-1} = \\frac{n}{n-1} s^2$, $s^2$: sample variance\n",
    "\n",
    "**The Weighted Mean**<br>\n",
    "This is to combine two or more measurements of the same quantity with different errors.<br>\n",
    "$\\hat{\\mu}= \\dfrac{\\Sigma x_i/\\sigma_i^2}{\\Sigma 1/\\sigma_i^2}$<br>\n",
    ", and error on the weighted mean:<br>\n",
    "$\\sigma^2(\\hat{\\mu})=\\dfrac{1}{\\Sigma 1/\\sigma^2_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case where $u=f(x,y)$ where x and y having errors $\\sigma_x$ and $\\sigma_y$, the variance of u can be written as:<br>\n",
    "$\\sigma_u^2 = \\bigg(\\dfrac{\\partial f}{\\partial x}\\bigg)^2 \\sigma_x^2 + \\bigg(\\dfrac{\\partial f}{\\partial y}\\bigg)^2 \\sigma_y^2 + 2 cov(x,y)\\bigg(\\dfrac{\\partial f}{\\partial x}\\bigg)\\bigg(\\dfrac{\\partial f}{\\partial y}\\bigg)$<br>\n",
    ", i.e. the errors are added quadratically with the modifying term due to the covariance.<br>\n",
    "In general, most measurements in physics are independent or should be arranged so that the covariance = 0. <br>\n",
    "Correlations can arise, when two or more parameters are extracted from the same set of measured data. One common example are **parameters from fit**. If these parameters are used in calculation, the correlation must be taken into account. <br>\n",
    "Another example is the **estimated mean and variance** from a set of data. Fortunatlely, the estimators for the Gaussian case are uncorrelated. \n",
    "\n",
    "**Formulas for error propagations:**\n",
    "1. Error of a sum: $u = x+y$<br>\n",
    "$\\sigma_u^2 = \\sigma_x^2 + \\sigma_y^2 + 2 cov(x,y)$<br>\n",
    "\n",
    "2. Error of a difference: $u = x-y$<br>\n",
    "$\\sigma_u^2 = \\sigma_x^2 + \\sigma_y^2 - 2 cov(x,y)$<br>\n",
    "\n",
    "3. Error of a product: $u = xy$<br>\n",
    "$\\dfrac{\\sigma_u^2}{u^2} \\approxeq \\dfrac{\\sigma_x^2}{\\sigma_x^2} + \\dfrac{\\sigma_y^2}{y^2} + 2 \\dfrac{cov(x,y)}{xy}$<br>\n",
    "\n",
    "4. Error of a ratio: $u=x/y$<br>\n",
    "$\\dfrac{\\sigma_u^2}{u^2} \\approxeq \\dfrac{\\sigma_x^2}{\\sigma_x^2} + \\dfrac{\\sigma_y^2}{y^2} - 2 \\dfrac{cov(x,y)}{xy}$<br>\n",
    "\n",
    "\n",
    "**Example: error propagation of asymmetry**<br>\n",
    "Asymmetry is given by:<br>\n",
    "$\\epsilon = \\dfrac{R-L}{R+L}$, where R/L are the counts at R/L detectors.<br>\n",
    "Using formula of propagation above, the variance is:<br>\n",
    "\\sigma^2(\\epsilon) \\approxeq 4\\dfrac{RL}{N_tot^3}<br>\n",
    "If the asymmetry is small such that $R\\approxeq L \\approxeq N_{tot}/2$, we have:<br>\n",
    " $\\sigma(\\epsilon) \\approxeq\\sqrt{\\dfrac{1}{N_{tot}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "attachments": {
    "variablesasobjects.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Least Squares Method\n",
    "\n",
    "We'd like to fit a function $f(x; a_1, a_2, ..., a_m)$, where $a_1 \\rightarrow a_m$ are the unknown parameters, to $n$ points of data $x_i$ and $y_i$ with y-error $\\sigma_i$.<br>\n",
    "The method of least squares states that the best values of $a_j$ are those which minimizes:<br>\n",
    "$S = \\Sigma_{i=1}^n \\bigg[\\frac{y_i - f(x_i;a_j)}{\\sigma_i}\\bigg]^2$<br>\n",
    ", which is the sum of the weighted residual (between data points and fit function). <br>\n",
    "This $S$ is basically the same formula as $\\chi^2$ and therefore sometimes called *chi-square minimization*, but strictly speaking $y_i$ must be Gaussian distributed with mean $f(x_i;a_j)$ and variance $\\sigma_i^2$ in order for S to be a true $\\chi^2$. However, this is almost always the case for measurements in physics. <br>\n",
    "The least squares method, does not require knowledge of the parent distribution. If the parent distribution is know, the method of maximum likelihood may also be used. \n",
    "\n",
    "To find values of $a_j, we need to solve the systems of equations:<br>\n",
    "$\\dfrac{\\partial S}{\\partial a_j} = 0$ <br>\n",
    "In general, numerical methods (matrix equation solver) must be used to minimize S. <br>\n",
    "\n",
    "To estimate error of the estimated $a_j$, we use the **covariance / error matrix $V_{ij}$**:<br>\n",
    "$(V^{-1}_{ij})= \\dfrac{1}{2}\\dfrac{\\partial^2 S}{\\partial a_i \\partial a_j}\\bigg|_\\text{evaluated at minimum}$\n",
    "![variablesasobjects.png](attachment:variablesasobjects.png)\n",
    "The diagonal part is the variances while the off-diagonals are co-variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Fit: The straight line\n",
    "\n",
    "We want to fit the data with straight line function:<br>\n",
    "$y = f(x) = a_1x+a_0$,<br>\n",
    "$S = \\Sigma\\dfrac{(y_i - a_1x_i - a_0)^2}{\\sigma_i^2}$.<br>\n",
    "___\n",
    "Jumping to Peter Young's Book: Everyting you wanted...\n",
    "___\n",
    "\n",
    "Minimizing this sum, S, gives an analytical solution:<br>\n",
    "$\\begin{aligned}\n",
    "U_{00}a_0 + U_{01}a_1 &= \\nu_0\\\\\n",
    "U_{10}a_0 + U_{11}a_1 &= \\nu_1\n",
    "\\end{aligned}$<br>\n",
    "\n",
    "where, <br>\n",
    "$\\begin{aligned}\n",
    "U_{\\alpha\\beta}&= \\Sigma_{i=1}^N\\dfrac{x_i^{\\alpha+\\beta}}{\\sigma_i^2}\\\\\n",
    "\\nu_\\alpha &= \\Sigma_{i=1}^N\\dfrac{y_i x_i^{\\alpha}}{\\sigma_i^2}\n",
    "\\end{aligned}$<br>\n",
    "\n",
    "The solution can be determined from:<br>\n",
    "$a_\\alpha = \\Sigma_{\\beta=0}^{M-1}\\big(U^{-1}\\big)_{\\alpha\\beta}\\nu_\\beta$<br>\n",
    "where the inverse of 2x2 matrices for this straight line can be expressed analytically as:<br>\n",
    "$U^{-1} = \\frac{1}{\\Delta}\\bigg(\\begin{matrix}U_{11}& -U_{01}\\\\ -U_{01}& U_{11}\\end{matrix}\\bigg)$<br>\n",
    "$\\Delta = U_{00}U_{11}-U_{01}^2$<br>\n",
    "The solutions are therefore:<br>\n",
    "$\\begin{aligned}\n",
    "a_0 &= \\dfrac{U_{11}\\nu_0 - U_{01}\\nu_1}{\\Delta}\\\\\n",
    "a_1 &= \\dfrac{-U_{01}\\nu_0 - U_{00}\\nu_1}{\\Delta}\n",
    "\\end{aligned}$\n",
    "\n",
    "___\n",
    "Back again to Leo's book:\n",
    "___\n",
    "Evaluating the **quality of the fit** can be done via the chi-square value, i.e. value of S at the minimum. If the data correspond to the function and the deviations ar Gaussian, S follow a chi-square distribution with mean value = $\\nu = n-m$ (degrees of freedom, n:# data points, m: # parameters). <br>\n",
    "For linear fit: $\\nu = n-2$.\n",
    "\n",
    "**A quick test**: reduced chi-square <br>\n",
    "$\\dfrac{\\chi^2}{\\nu} = \\dfrac{S}{\\nu} \\approxeq 1$  for a good fit\n",
    "\n",
    "**More rigorous test**: p-value<br>\n",
    "This is done by integrating the chi-square or using cumulative distributioin tables. <br>\n",
    "If $P(\\chi^2 \\geq S)$ is greater than 5%, the fit can be accepted. Beyond this point, some questions must be asked. \n",
    "\n",
    "*Additional note:*<br>\n",
    "When the obtained value S is very small, this means data points are not fluctuating enough. The most likely cause is an *overestimation of the errors on the data points*.<br>\n",
    "In general, since error bars represent a $1\\sigma$ deviation, out of all the data points, 1/3 should be expected to fall outside the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
